{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo que detecta si la persona pisa o no el punto del suelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Inicializar BlazePose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Define area to mark (e.g., a bounding box)\n",
    "rectangles = [\n",
    "    (541, 604, 587, 630),  # Coordenadas de los círculos en el piso\n",
    "    (171, 525, 218, 550),\n",
    "    (162, 390, 197, 408),\n",
    "    (923, 373, 953, 389),\n",
    "    (905, 504, 946, 526),\n",
    "    (768, 299, 793, 311),\n",
    "    (338, 305, 367, 319),\n",
    "    (553, 381, 585, 396),\n",
    "    (559, 279, 582, 289)\n",
    "]\n",
    "\n",
    "def average_landmarks_three(landmark1, landmark2, landmark3):\n",
    "    return {\n",
    "        'x': (landmark1.x + landmark2.x + landmark3.x) / 3,\n",
    "        'y': (landmark1.y + landmark2.y + landmark3.y) / 3,\n",
    "        'visibility': (landmark1.visibility + landmark2.visibility + landmark3.visibility) / 3\n",
    "    }\n",
    "\n",
    "def average_landmarks(landmark1, landmark2):\n",
    "    return {\n",
    "        'x': (landmark1.x + landmark2.x) / 2,\n",
    "        'y': (landmark1.y + landmark2.y) / 2,\n",
    "        'visibility': (landmark1.visibility + landmark2.visibility) / 2\n",
    "    }\n",
    "\n",
    "def convert_blazepose_to_coco(landmarks, image_shape):\n",
    "    keypoints = [None] * 25\n",
    "    keypoints[0] = landmarks[0]  # Nose\n",
    "    keypoints[1] = average_landmarks(landmarks[12], landmarks[11])  # Neck\n",
    "    keypoints[2] = landmarks[12]  # L shoulder\n",
    "    keypoints[3] = landmarks[14]  # L elbow \n",
    "    keypoints[4] = landmarks[16]  # L hand\n",
    "    keypoints[5] = landmarks[11]  # R shoulder\n",
    "    keypoints[6] = landmarks[13]  # R elbow\n",
    "    keypoints[7] = landmarks[15]  # R hand\n",
    "    keypoints[8] = average_landmarks(landmarks[24], landmarks[23])  # Hip central pelvis\n",
    "    keypoints[9] = landmarks[24]  # L hip\n",
    "    keypoints[10] = landmarks[26]  # L knee\n",
    "    keypoints[11] = landmarks[28]  # L ankle\n",
    "    keypoints[12] = landmarks[23]  # R hip\n",
    "    keypoints[13] = landmarks[25]  # R knee\n",
    "    keypoints[14] = landmarks[27]  # R ankle\n",
    "    keypoints[15] = average_landmarks_three(landmarks[5], landmarks[6], landmarks[4])  # Average of points\n",
    "    keypoints[16] = average_landmarks_three(landmarks[1], landmarks[2], landmarks[3])  # Average of points\n",
    "    keypoints[17] = landmarks[8]  # Custom point\n",
    "    keypoints[18] = landmarks[7]  # Custom point\n",
    "    keypoints[19] = landmarks[29]  # Custom point\n",
    "    keypoints[21] = landmarks[31]  # Custom point\n",
    "    keypoints[22] = landmarks[30]  # Custom point\n",
    "    keypoints[24] = landmarks[32]  # Custom point\n",
    "\n",
    "    coco_keypoints = []\n",
    "    for point in keypoints:\n",
    "        if point is not None:\n",
    "            if isinstance(point, dict):\n",
    "                coco_keypoints.extend([point['x'] * image_shape[1], point['y'] * image_shape[0], point['visibility']])\n",
    "            else:\n",
    "                coco_keypoints.extend([point.x * image_shape[1], point.y * image_shape[0], point.visibility])\n",
    "        else:\n",
    "            coco_keypoints.extend([0, 0, 0])\n",
    "    return coco_keypoints\n",
    "\n",
    "def draw_coco_keypoints(image, keypoints):\n",
    "    for i in range(0, len(keypoints), 3):\n",
    "        x, y, v = keypoints[i:i+3]\n",
    "        if v > 0:\n",
    "            cv2.circle(image, (int(x), int(y)), 5, (0, 255, 0), -1)\n",
    "            cv2.putText(image, str(i//3), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "def draw_coco_skeleton(image, keypoints, pairs):\n",
    "    for (start, end) in pairs:\n",
    "        x1, y1, v1 = keypoints[start*3:start*3+3]\n",
    "        x2, y2, v2 = keypoints[end*3:end*3+3]\n",
    "        if v1 > 0 and v2 > 0:\n",
    "            cv2.line(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "\n",
    "def point_in_rectangle(point, rect):\n",
    "    x, y = point\n",
    "    x1, y1, x2, y2 = rect\n",
    "    return x1 <= x <= x2 and y1 <= y <= y2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar el video\n",
    "video_url = 'https://mcp-wildsense.s3.us-east-2.amazonaws.com/videos/7/2024-03-15/11_28_22-player9.mp4'\n",
    "cap = cv2.VideoCapture(video_url)\n",
    "#cap = cv2.VideoCapture('./caminar2.mp4')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('outputFinal.mp4', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "blazepose_results = []\n",
    "previous_left_ankle = None\n",
    "previous_right_ankle = None\n",
    "steps = 0\n",
    "step_threshold = 25  # Umbral de distancia para considerar un paso (ajusta según sea necesario)\n",
    "still_threshold = 20  # Umbral de distancia para considerar que la persona está quieta\n",
    "still_frames = 0\n",
    "still_frames_threshold = 10  # Número de cuadros consecutivos para considerar que la persona está quieta\n",
    "is_still = False\n",
    "movement_direction = None\n",
    "movement_threshold = 10  # Umbral de movimiento en el eje X para considerar desplazamiento lateral\n",
    "distance_direction = None\n",
    "distance_threshold = 8  # Umbral de movimiento en el eje Y para considerar acercamiento/alejamiento\n",
    "#con 10 y 6 tambien funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    for rect in rectangles:\n",
    "        cv2.rectangle(frame, (rect[0], rect[1]), (rect[2], rect[3]), (255, 0, 0), 2)  # Draw rectangles\n",
    "\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(image_rgb)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        \n",
    "        keypoints = convert_blazepose_to_coco(results.pose_landmarks.landmark, frame.shape)\n",
    "        \n",
    "        draw_coco_keypoints(frame, keypoints)\n",
    "        skeleton_pairs = [\n",
    "            (0, 15), (15, 17), (0, 16), (16, 18), # Cabeza \n",
    "            (0, 1), #cuello\n",
    "            (1, 2), (2, 3), (3,4), #Brazo izquierdo\n",
    "            (1, 5), (6, 7), (5,6), # Brazos derechos\n",
    "            (1,8), #torso\n",
    "            (8, 9), (9, 10), (10, 11), (11, 22), (22, 24),  # Pierna izquierda\n",
    "            (8, 12), (12, 13), (13, 14), (14, 19), (19,21)  # Pierna derecha\n",
    "        ]\n",
    "        draw_coco_skeleton(frame, keypoints, skeleton_pairs)\n",
    "\n",
    "        #left_ankle = np.array([keypoints[35], keypoints[36]])  # Coordenadas del tobillo izquierdo\n",
    "        #right_ankle = np.array([keypoints[39], keypoints[40]])  # Coordenadas del tobillo derecho\n",
    "    \n",
    "    #con este funciona mejor\n",
    "        #left_ankle = np.array([keypoints[33], keypoints[34]])  # Coordenadas del tobillo izquierdo\n",
    "        #right_ankle = np.array([keypoints[39], keypoints[40]])  # Coordenadas del tobillo derecho\n",
    "\n",
    "        left_ankle = np.array([keypoints[11*3], keypoints[11*3+1]])  # Coordenadas del tobillo izquierdo\n",
    "        right_ankle = np.array([keypoints[14*3], keypoints[14*3+1]])   # Coordenadas del tobillo derecho\n",
    "\n",
    "        tip_toe_left = np.array([keypoints[24*3], keypoints[24*3+1]])\n",
    "        tip_toe_right = np.array([keypoints[21*3], keypoints[21*3+1]])\n",
    "\n",
    "        heel_left = np.array([keypoints[22*3], keypoints[22*3+1]])\n",
    "        heel_right = np.array([keypoints[19*3], keypoints[19*3+1]])\n",
    "\n",
    "        # Promedio de puntos\n",
    "        average_left_foot = (left_ankle + tip_toe_left + heel_left) / 3\n",
    "        average_right_foot = (right_ankle + tip_toe_right + heel_right) / 3\n",
    "\n",
    "        #pintar el punto promedio del pie\n",
    "        average_left_foot_paint = average_left_foot.astype(int)\n",
    "        average_right_foot_paint = average_right_foot.astype(int)\n",
    "\n",
    "        cv2.circle(frame, tuple(average_left_foot_paint), 5, (51, 255, 252), -1)\n",
    "        cv2.circle(frame, tuple(average_right_foot_paint), 5, (51, 255, 252), -1)\n",
    "\n",
    "        for rect in rectangles:\n",
    "            if point_in_rectangle(average_left_foot, rect):\n",
    "                cv2.putText(frame, 'Left Ankle in Area', (rect[0], rect[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            if point_in_rectangle(average_right_foot, rect):\n",
    "                cv2.putText(frame, 'Right Ankle in Area', (rect[0], rect[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        if previous_left_ankle is not None and previous_right_ankle is not None:\n",
    "            left_distance = np.linalg.norm(average_left_foot - previous_left_ankle)\n",
    "            right_distance = np.linalg.norm(average_right_foot - previous_right_ankle)\n",
    "            if left_distance > step_threshold or right_distance > step_threshold:\n",
    "                steps += 1\n",
    "\n",
    "            if left_distance < still_threshold and right_distance < still_threshold:\n",
    "                still_frames += 1\n",
    "            else:\n",
    "                still_frames = 0\n",
    "\n",
    "            is_still = still_frames >= still_frames_threshold\n",
    "\n",
    "            left_movement_x = average_left_foot[0] - previous_left_ankle[0]\n",
    "            right_movement_x = average_right_foot[0] - previous_right_ankle[0]\n",
    "\n",
    "            if abs(left_movement_x) > movement_threshold or abs(right_movement_x) > movement_threshold:\n",
    "                if left_movement_x > 0 and right_movement_x > 0:\n",
    "                    movement_direction = \"Right\"\n",
    "                elif left_movement_x < 0 and right_movement_x < 0:\n",
    "                    movement_direction = \"Left\"\n",
    "                else:\n",
    "                    movement_direction = \"Unknown\"\n",
    "            else:\n",
    "                movement_direction = \"Still\"\n",
    "\n",
    "            left_movement_y = average_left_foot[1] - previous_left_ankle[1]\n",
    "            right_movement_y = average_right_foot[1] - previous_right_ankle[1]\n",
    "\n",
    "            if abs(left_movement_y) > distance_threshold or abs(right_movement_y) > distance_threshold:\n",
    "                if left_movement_y > 0 and right_movement_y > 0:\n",
    "                    distance_direction = \"Closer\"\n",
    "                    steps += 1\n",
    "                elif left_movement_y < 0 and right_movement_y < 0:\n",
    "                    distance_direction = \"Farther\"\n",
    "                    steps += 1\n",
    "                else:\n",
    "                    distance_direction = \"Unknown\"\n",
    "            else:\n",
    "                distance_direction = \"Stationary\"\n",
    "\n",
    "        previous_left_ankle = average_left_foot\n",
    "        previous_right_ankle = average_right_foot\n",
    "\n",
    "        ann = {\n",
    "            \"image_id\": \"videoframe\",\n",
    "            \"category_id\": 1,\n",
    "            \"keypoints\": keypoints,\n",
    "            \"score\": 1.0\n",
    "        }\n",
    "        blazepose_results.append(ann)\n",
    "\n",
    "    #status_text = f\"Steps: {steps} - Still: {'Yes' if is_still else 'No'} - Moving: {movement_direction} - Distance: {distance_direction}\"\n",
    "    status_text = f\"Still: {'Yes' if is_still else 'No'} - Moving: {movement_direction} - Distance: {distance_direction}\"\n",
    "\n",
    "    cv2.putText(frame, status_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    out.write(frame)\n",
    "    cv2.imshow('BlazePose Result', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "pose.close()\n",
    "\n",
    "with open('blazepose_results_finalDetection.json', 'w') as f:\n",
    "    json.dump(blazepose_results, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
