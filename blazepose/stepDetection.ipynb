{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este codigo era para usar con la estimacino de open pose pero no detecta los pasos aun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Inicializar BlazePose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def average_landmarks(landmark1, landmark2):\n",
    "    return {\n",
    "        'x': (landmark1.x + landmark2.x) / 2,\n",
    "        'y': (landmark1.y + landmark2.y) / 2,\n",
    "        'visibility': (landmark1.visibility + landmark2.visibility) / 2\n",
    "    }\n",
    "\n",
    "def average_landmarks_three(landmark1, landmark2, landmark3):\n",
    "    return {\n",
    "        'x': (landmark1.x + landmark2.x + landmark3.x) / 3,\n",
    "        'y': (landmark1.y + landmark2.y + landmark3.y) / 3,\n",
    "        'visibility': (landmark1.visibility + landmark2.visibility + landmark3.visibility) / 3\n",
    "    }\n",
    "\n",
    "def convert_blazepose_to_openpose(landmarks):\n",
    "    keypoints = [None] * 25\n",
    "    keypoints[0] = landmarks[0]  # Nose\n",
    "    keypoints[1] = average_landmarks(landmarks[12], landmarks[11])  # Neck\n",
    "    keypoints[2] = landmarks[12]  # L shoulder\n",
    "    keypoints[3] = landmarks[14]  # L elbow \n",
    "    keypoints[4] = landmarks[16]  # L hand\n",
    "    keypoints[5] = landmarks[11]  # R shoulder\n",
    "    keypoints[6] = landmarks[13]  # R elbow\n",
    "    keypoints[7] = landmarks[15]  # R hand\n",
    "    keypoints[8] = average_landmarks(landmarks[24], landmarks[23])  # Hip central pelvis\n",
    "    keypoints[9] = landmarks[24]  # L hip\n",
    "    keypoints[10] = landmarks[26]  # L knee\n",
    "    keypoints[11] = landmarks[28]  # L ankle\n",
    "    keypoints[12] = landmarks[23]  # R hip\n",
    "    keypoints[13] = landmarks[25]  # R knee\n",
    "    keypoints[14] = landmarks[27]  # R ankle\n",
    "    keypoints[15] = average_landmarks_three(landmarks[5], landmarks[6], landmarks[4])  # Average of points\n",
    "    keypoints[16] = average_landmarks_three(landmarks[1], landmarks[2], landmarks[3])  # Average of points\n",
    "    keypoints[17] = landmarks[8]  # Custom point\n",
    "    keypoints[18] = landmarks[7]  # Custom point\n",
    "    keypoints[19] = landmarks[29]  # Custom point\n",
    "    keypoints[21] = landmarks[31]  # Custom point\n",
    "    keypoints[22] = landmarks[30]  # Custom point\n",
    "    keypoints[24] = landmarks[32]  # Custom point\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "def draw_openpose_keypoints(image, keypoints):\n",
    "    for idx, point in enumerate(keypoints):\n",
    "        if point is not None:\n",
    "            if isinstance(point, dict):\n",
    "                x, y = int(point['x'] * image.shape[1]), int(point['y'] * image.shape[0])\n",
    "            else:\n",
    "                x, y = int(point.x * image.shape[1]), int(point.y * image.shape[0])\n",
    "            cv2.circle(image, (x, y), 5, (0, 255, 0), -1)\n",
    "            cv2.putText(image, str(idx), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "def draw_openpose_skeleton(image, keypoints, pairs):\n",
    "    for start, end in pairs:\n",
    "        if keypoints[start] is not None and keypoints[end] is not None:\n",
    "            if isinstance(keypoints[start], dict):\n",
    "                x1, y1 = int(keypoints[start]['x'] * image.shape[1]), int(keypoints[start]['y'] * image.shape[0])\n",
    "            else:\n",
    "                x1, y1 = int(keypoints[start].x * image.shape[1]), int(keypoints[start].y * image.shape[0])\n",
    "            if isinstance(keypoints[end], dict):\n",
    "                x2, y2 = int(keypoints[end]['x'] * image.shape[1]), int(keypoints[end]['y'] * image.shape[0])\n",
    "            else:\n",
    "                x2, y2 = int(keypoints[end].x * image.shape[1]), int(keypoints[end].y * image.shape[0])\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            \n",
    "def point_in_rectangle(point, rect):\n",
    "    x, y = point\n",
    "    x1, y1, x2, y2 = rect\n",
    "    return x1 <= x <= x2 and y1 <= y <= y2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Leer la imagen\\nimage_path = '../yolo/videoframe_0.jpg'\\nimage = cv2.imread(image_path)\\nimage_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\\nresults = pose.process(image_rgb)\\n\\nif results.pose_landmarks:\\n    keypoints = convert_blazepose_to_openpose(results.pose_landmarks.landmark)\\n    draw_openpose_keypoints(image, keypoints)\\n    \\n    # Pairs of points to connect for the skeleton\\n    skeleton_pairs = [\\n            (0, 15), (15, 17), (0, 16), (16, 18), # Cabeza \\n            (0, 1), #cuello\\n            (1, 2), (2, 3), (3,4), #Brazo izquierdo\\n            (1, 5), (6, 7), (5,6), # Brazos derechos\\n            (1,8), #torso\\n            (8, 9), (9, 10), (10, 11), (11, 22), (22, 24),  # Pierna izquierda\\n            (8, 12), (12, 13), (13, 14), (14, 19), (19,21)  # Pierna derecha\\n        ]\\n    \\n    draw_openpose_skeleton(image, keypoints, skeleton_pairs)\\n\\ncv2.imshow('OpenPose Keypoints', image)\\ncv2.waitKey(0)\\ncv2.destroyAllWindows()\\npose.close() \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define area to mark (e.g., a bounding box)\n",
    "rectangles = [\n",
    "    (541, 604, 587, 630),  # Coordenadas de los círculos en el piso\n",
    "    (171, 525, 218, 550),\n",
    "    (162, 390, 197, 408),\n",
    "    (923, 373, 953, 389),\n",
    "    (905, 504, 946, 526),\n",
    "    (768, 299, 793, 311),\n",
    "    (338, 305, 367, 319),\n",
    "    (553, 381, 585, 396),\n",
    "    (559, 279, 582, 289)\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\" # Leer la imagen\n",
    "image_path = '../yolo/videoframe_0.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "results = pose.process(image_rgb)\n",
    "\n",
    "if results.pose_landmarks:\n",
    "    keypoints = convert_blazepose_to_openpose(results.pose_landmarks.landmark)\n",
    "    draw_openpose_keypoints(image, keypoints)\n",
    "    \n",
    "    # Pairs of points to connect for the skeleton\n",
    "    skeleton_pairs = [\n",
    "            (0, 15), (15, 17), (0, 16), (16, 18), # Cabeza \n",
    "            (0, 1), #cuello\n",
    "            (1, 2), (2, 3), (3,4), #Brazo izquierdo\n",
    "            (1, 5), (6, 7), (5,6), # Brazos derechos\n",
    "            (1,8), #torso\n",
    "            (8, 9), (9, 10), (10, 11), (11, 22), (22, 24),  # Pierna izquierda\n",
    "            (8, 12), (12, 13), (13, 14), (14, 19), (19,21)  # Pierna derecha\n",
    "        ]\n",
    "    \n",
    "    draw_openpose_skeleton(image, keypoints, skeleton_pairs)\n",
    "\n",
    "cv2.imshow('OpenPose Keypoints', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "pose.close() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'int' and 'NormalizedLandmark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m right_ankle \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([keypoints[\u001b[38;5;241m19\u001b[39m], keypoints[\u001b[38;5;241m21\u001b[39m]])  \u001b[38;5;66;03m# Coordenadas del tobillo derecho\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rect \u001b[38;5;129;01min\u001b[39;00m rectangles:\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpoint_in_rectangle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_ankle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrect\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     56\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLeft Ankle in Area\u001b[39m\u001b[38;5;124m'\u001b[39m, (rect[\u001b[38;5;241m0\u001b[39m], rect[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.5\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m point_in_rectangle(right_ankle, rect):\n",
      "Cell \u001b[1;32mIn[2], line 79\u001b[0m, in \u001b[0;36mpoint_in_rectangle\u001b[1;34m(point, rect)\u001b[0m\n\u001b[0;32m     77\u001b[0m x, y \u001b[38;5;241m=\u001b[39m point\n\u001b[0;32m     78\u001b[0m x1, y1, x2, y2 \u001b[38;5;241m=\u001b[39m rect\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m y1 \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m y2\n",
      "\u001b[1;31mTypeError\u001b[0m: '<=' not supported between instances of 'int' and 'NormalizedLandmark'"
     ]
    }
   ],
   "source": [
    "# Cargar el video\n",
    "video_url = 'https://mcp-wildsense.s3.us-east-2.amazonaws.com/videos/7/2024-03-15/11_28_22-player9.mp4'\n",
    "cap = cv2.VideoCapture(video_url)\n",
    "#cap = cv2.VideoCapture('./caminar2.mp4')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "blazepose_results = []\n",
    "previous_left_ankle = None\n",
    "previous_right_ankle = None\n",
    "steps = 0\n",
    "step_threshold = 30  # Umbral de distancia para considerar un paso (ajusta según sea necesario)\n",
    "still_threshold = 40  # Umbral de distancia para considerar que la persona está quieta\n",
    "still_frames = 0\n",
    "still_frames_threshold = 15  # Número de cuadros consecutivos para considerar que la persona está quieta\n",
    "is_still = False\n",
    "movement_direction = None\n",
    "movement_threshold = 10  # Umbral de movimiento en el eje X para considerar desplazamiento lateral\n",
    "distance_direction = None\n",
    "distance_threshold = 6  # Umbral de movimiento en el eje Y para considerar acercamiento/alejamiento\n",
    "\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    for rect in rectangles:\n",
    "        cv2.rectangle(frame, (rect[0], rect[1]), (rect[2], rect[3]), (255, 0, 0), 2)  # Draw rectangles\n",
    "\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(image_rgb)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        keypoints = convert_blazepose_to_openpose(results.pose_landmarks.landmark)\n",
    "        draw_openpose_keypoints(image_rgb, keypoints)\n",
    "        \n",
    "        # Pairs of points to connect for the skeleton\n",
    "        skeleton_pairs = [\n",
    "                (0, 15), (15, 17), (0, 16), (16, 18), # Cabeza \n",
    "                (0, 1), #cuello\n",
    "                (1, 2), (2, 3), (3,4), #Brazo izquierdo\n",
    "                (1, 5), (6, 7), (5,6), # Brazos derechos\n",
    "                (1,8), #torso\n",
    "                (8, 9), (9, 10), (10, 11), (11, 22), (22, 24),  # Pierna izquierda\n",
    "                (8, 12), (12, 13), (13, 14), (14, 19), (19,21)  # Pierna derecha\n",
    "            ]\n",
    "        \n",
    "        draw_openpose_skeleton(image_rgb, keypoints, skeleton_pairs)\n",
    "        left_ankle = np.array([keypoints[22], keypoints[24]])  # Coordenadas del tobillo izquierdo\n",
    "        right_ankle = np.array([keypoints[19], keypoints[21]])  # Coordenadas del tobillo derecho\n",
    "\n",
    "        for rect in rectangles:\n",
    "            if point_in_rectangle(left_ankle, rect):\n",
    "                cv2.putText(frame, 'Left Ankle in Area', (rect[0], rect[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            if point_in_rectangle(right_ankle, rect):\n",
    "                cv2.putText(frame, 'Right Ankle in Area', (rect[0], rect[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        if previous_left_ankle is not None and previous_right_ankle is not None:\n",
    "            left_distance = np.linalg.norm(left_ankle - previous_left_ankle)\n",
    "            right_distance = np.linalg.norm(right_ankle - previous_right_ankle)\n",
    "            if left_distance > step_threshold or right_distance > step_threshold:\n",
    "                steps += 1\n",
    "\n",
    "            if left_distance < still_threshold and right_distance < still_threshold:\n",
    "                still_frames += 1\n",
    "            else:\n",
    "                still_frames = 0\n",
    "\n",
    "            is_still = still_frames >= still_frames_threshold\n",
    "\n",
    "            left_movement_x = left_ankle[0] - previous_left_ankle[0]\n",
    "            right_movement_x = right_ankle[0] - previous_right_ankle[0]\n",
    "\n",
    "            if abs(left_movement_x) > movement_threshold or abs(right_movement_x) > movement_threshold:\n",
    "                if left_movement_x > 0 and right_movement_x > 0:\n",
    "                    movement_direction = \"Right\"\n",
    "                elif left_movement_x < 0 and right_movement_x < 0:\n",
    "                    movement_direction = \"Left\"\n",
    "                else:\n",
    "                    movement_direction = \"Unknown\"\n",
    "            else:\n",
    "                movement_direction = \"Still\"\n",
    "\n",
    "            left_movement_y = left_ankle[1] - previous_left_ankle[1]\n",
    "            right_movement_y = right_ankle[1] - previous_right_ankle[1]\n",
    "\n",
    "            if abs(left_movement_y) > distance_threshold or abs(right_movement_y) > distance_threshold:\n",
    "                if left_movement_y > 0 and right_movement_y > 0:\n",
    "                    distance_direction = \"Closer\"\n",
    "                    steps += 1\n",
    "                elif left_movement_y < 0 and right_movement_y < 0:\n",
    "                    distance_direction = \"Farther\"\n",
    "                    steps += 1\n",
    "                else:\n",
    "                    distance_direction = \"Unknown\"\n",
    "            else:\n",
    "                distance_direction = \"Stationary\"\n",
    "\n",
    "        previous_left_ankle = left_ankle\n",
    "        previous_right_ankle = right_ankle\n",
    "\n",
    "        ann = {\n",
    "            \"image_id\": \"videoframe\",\n",
    "            \"category_id\": 1,\n",
    "            \"keypoints\": keypoints,\n",
    "            \"score\": 1.0\n",
    "        }\n",
    "        blazepose_results.append(ann)\n",
    "\n",
    "    status_text = f\"Steps: {steps} - Still: {'Yes' if is_still else 'No'} - Moving: {movement_direction} - Distance: {distance_direction}\"\n",
    "    cv2.putText(frame, status_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    out.write(frame)\n",
    "    cv2.imshow('BlazePose Result', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "pose.close()\n",
    "\n",
    "with open('blazepose_results.json', 'w') as f:\n",
    "    json.dump(blazepose_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\franf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type NormalizedLandmark is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 199\u001b[0m\n\u001b[0;32m    196\u001b[0m pose\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblazepose_results_to_openpose.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 199\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblazepose_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\franf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[0;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[0;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[0;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[1;32mc:\\Users\\franf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:430\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m _floatstr(o)\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n",
      "File \u001b[1;32mc:\\Users\\franf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[1;34m(lst, _current_indent_level)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\franf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\franf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[1;34m(lst, _current_indent_level)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\franf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[1;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\franf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type NormalizedLandmark is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Inicializar BlazePose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "def average_landmarks(landmark1, landmark2):\n",
    "    return {\n",
    "        'x': (landmark1.x + landmark2.x) / 2,\n",
    "        'y': (landmark1.y + landmark2.y) / 2,\n",
    "        'visibility': (landmark1.visibility + landmark2.visibility) / 2\n",
    "    }\n",
    "\n",
    "def average_landmarks_three(landmark1, landmark2, landmark3):\n",
    "    return {\n",
    "        'x': (landmark1.x + landmark2.x + landmark3.x) / 3,\n",
    "        'y': (landmark1.y + landmark2.y + landmark3.y) / 3,\n",
    "        'visibility': (landmark1.visibility + landmark2.visibility + landmark3.visibility) / 3\n",
    "    }\n",
    "\n",
    "def convert_blazepose_to_openpose(landmarks):\n",
    "    keypoints = [None] * 25\n",
    "\n",
    "    keypoints[0] = landmarks[0]  # Nose\n",
    "    keypoints[1] = average_landmarks(landmarks[12], landmarks[11])  # Neck\n",
    "    keypoints[2] = landmarks[12]  # L shoulder\n",
    "    keypoints[3] = landmarks[14]  # L elbow \n",
    "    keypoints[4] = landmarks[16]  # L hand\n",
    "    keypoints[5] = landmarks[11]  # R shoulder\n",
    "    keypoints[6] = landmarks[13]  # R elbow\n",
    "    keypoints[7] = landmarks[15]  # R hand\n",
    "    keypoints[8] = average_landmarks(landmarks[24], landmarks[23])  # Hip central pelvis\n",
    "    keypoints[9] = landmarks[24]  # L hip\n",
    "    keypoints[10] = landmarks[26]  # L knee\n",
    "    keypoints[11] = landmarks[28]  # L ankle\n",
    "    keypoints[12] = landmarks[23]  # R hip\n",
    "    keypoints[13] = landmarks[25]  # R knee\n",
    "    keypoints[14] = landmarks[27]  # R ankle\n",
    "    keypoints[15] = average_landmarks_three(landmarks[5], landmarks[6], landmarks[4])  # Average of points\n",
    "    keypoints[16] = average_landmarks_three(landmarks[1], landmarks[2], landmarks[3])  # Average of points\n",
    "    keypoints[17] = landmarks[8]  # Custom point\n",
    "    keypoints[18] = landmarks[7]  # Custom point\n",
    "    keypoints[19] = landmarks[29]  # Custom point\n",
    "    keypoints[21] = landmarks[31]  # Custom point\n",
    "    keypoints[22] = landmarks[30]  # Custom point\n",
    "    keypoints[24] = landmarks[32]\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "def draw_openpose_keypoints(image, keypoints):\n",
    "    for idx, point in enumerate(keypoints):\n",
    "        if point is not None:\n",
    "            if isinstance(point, dict):\n",
    "                x, y = int(point['x'] * image.shape[1]), int(point['y'] * image.shape[0])\n",
    "            else:\n",
    "                x, y = int(point.x * image.shape[1]), int(point.y * image.shape[0])\n",
    "            cv2.circle(image, (x, y), 5, (0, 255, 0), -1)\n",
    "            cv2.putText(image, str(idx), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "def draw_openpose_skeleton(image, keypoints, pairs):\n",
    "    for start, end in pairs:\n",
    "        if keypoints[start] is not None and keypoints[end] is not None:\n",
    "            if isinstance(keypoints[start], dict):\n",
    "                x1, y1 = int(keypoints[start]['x'] * image.shape[1]), int(keypoints[start]['y'] * image.shape[0])\n",
    "            else:\n",
    "                x1, y1 = int(keypoints[start].x * image.shape[1]), int(keypoints[start].y * image.shape[0])\n",
    "            if isinstance(keypoints[end], dict):\n",
    "                x2, y2 = int(keypoints[end]['x'] * image.shape[1]), int(keypoints[end]['y'] * image.shape[0])\n",
    "            else:\n",
    "                x2, y2 = int(keypoints[end].x * image.shape[1]), int(keypoints[end].y * image.shape[0])\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "# Cargar el video\n",
    "video_url = 'https://mcp-wildsense.s3.us-east-2.amazonaws.com/videos/7/2024-03-15/11_28_22-player9.mp4'\n",
    "cap = cv2.VideoCapture(video_url)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "blazepose_results = []\n",
    "previous_left_ankle = None\n",
    "previous_right_ankle = None\n",
    "steps = 0\n",
    "step_threshold = 30  # Umbral de distancia para considerar un paso (ajusta según sea necesario)\n",
    "still_threshold = 40  # Umbral de distancia para considerar que la persona está quieta\n",
    "still_frames = 0\n",
    "still_frames_threshold = 15  # Número de cuadros consecutivos para considerar que la persona está quieta\n",
    "is_still = False\n",
    "movement_direction = None\n",
    "movement_threshold = 10  # Umbral de movimiento en el eje X para considerar desplazamiento lateral\n",
    "distance_direction = None\n",
    "distance_threshold = 6  # Umbral de movimiento en el eje Y para considerar acercamiento/alejamiento\n",
    "\n",
    "rectangles = []  # Añade aquí los rectángulos que deseas dibujar y comprobar\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    for rect in rectangles:\n",
    "        cv2.rectangle(frame, (rect[0], rect[1]), (rect[2], rect[3]), (255, 0, 0), 2)  # Draw rectangles\n",
    "\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(image_rgb)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        keypoints = convert_blazepose_to_openpose(results.pose_landmarks.landmark)\n",
    "        draw_openpose_keypoints(frame, keypoints)\n",
    "        \n",
    "        # Pairs of points to connect for the skeleton\n",
    "        skeleton_pairs = [\n",
    "        (0, 15), (15, 17), (0, 16), (16, 18), # Cabeza \n",
    "        (0, 1), #cuello\n",
    "        (1, 2), (2, 3), (3,4), #Brazo izquierdo\n",
    "        (1, 5), (6, 7), (5,6), # Brazos derechos\n",
    "        (1,8), #torso\n",
    "        (8, 9), (9, 10), (10, 11), (11, 22), (22, 24),  # Pierna izquierda\n",
    "        (8, 12), (12, 13), (13, 14), (14, 19), (19,21)  # Pierna derecha\n",
    "    ]\n",
    "        \n",
    "        draw_openpose_skeleton(frame, keypoints, skeleton_pairs)\n",
    "        left_ankle = np.array([keypoints[11].x, keypoints[11].y, keypoints[11].z])\n",
    "        right_ankle = np.array([keypoints[14].x, keypoints[14].y, keypoints[14].z])\n",
    "\n",
    "        for rect in rectangles:\n",
    "            if point_in_rectangle(left_ankle, rect):\n",
    "                cv2.putText(frame, 'Left Ankle in Area', (rect[0], rect[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            if point_in_rectangle(right_ankle, rect):\n",
    "                cv2.putText(frame, 'Right Ankle in Area', (rect[0], rect[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        if previous_left_ankle is not None and previous_right_ankle is not None:\n",
    "            left_distance = np.linalg.norm(left_ankle - previous_left_ankle)\n",
    "            right_distance = np.linalg.norm(right_ankle - previous_right_ankle)\n",
    "            if left_distance > step_threshold or right_distance > step_threshold:\n",
    "                steps += 1\n",
    "\n",
    "            if left_distance < still_threshold and right_distance < still_threshold:\n",
    "                still_frames += 1\n",
    "            else:\n",
    "                still_frames = 0\n",
    "\n",
    "            is_still = still_frames >= still_frames_threshold\n",
    "\n",
    "            left_movement_x = left_ankle[0] - previous_left_ankle[0]\n",
    "            right_movement_x = right_ankle[0] - previous_right_ankle[0]\n",
    "\n",
    "            if abs(left_movement_x) > movement_threshold or abs(right_movement_x) > movement_threshold:\n",
    "                if left_movement_x > 0 and right_movement_x > 0:\n",
    "                    movement_direction = \"Right\"\n",
    "                elif left_movement_x < 0 and right_movement_x < 0:\n",
    "                    movement_direction = \"Left\"\n",
    "                else:\n",
    "                    movement_direction = \"Unknown\"\n",
    "            else:\n",
    "                movement_direction = \"Still\"\n",
    "\n",
    "            left_movement_y = left_ankle[1] - previous_left_ankle[1]\n",
    "            right_movement_y = right_ankle[1] - previous_right_ankle[1]\n",
    "\n",
    "            if abs(left_movement_y) > distance_threshold or abs(right_movement_y) > distance_threshold:\n",
    "                if left_movement_y > 0 and right_movement_y > 0:\n",
    "                    distance_direction = \"Closer\"\n",
    "                    steps += 1\n",
    "                elif left_movement_y < 0 and right_movement_y < 0:\n",
    "                    distance_direction = \"Farther\"\n",
    "                    steps += 1\n",
    "                else:\n",
    "                    distance_direction = \"Unknown\"\n",
    "            else:\n",
    "                distance_direction = \"Stationary\"\n",
    "        \n",
    "        previous_left_ankle = left_ankle\n",
    "        previous_right_ankle = right_ankle\n",
    "\n",
    "        ann = {\n",
    "            \"image_id\": \"videoframe\",\n",
    "            \"category_id\": 1,\n",
    "            \"keypoints\": keypoints,\n",
    "            \"score\": 1.0\n",
    "        }\n",
    "        blazepose_results.append(ann)\n",
    "\n",
    "    status_text = f\"Steps: {steps} - Still: {'Yes' if is_still else 'No'} - Moving: {movement_direction} - Distance: {distance_direction}\"\n",
    "    cv2.putText(frame, status_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    out.write(frame)\n",
    "    cv2.imshow('BlazePose Result', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "pose.close()\n",
    "\n",
    "with open('blazepose_results_to_openpose.json', 'w') as f:\n",
    "    json.dump(blazepose_results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
